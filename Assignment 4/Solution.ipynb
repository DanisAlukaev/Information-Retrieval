{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment 4 - Sugges_\n",
    "\n",
    "**Author:** Danis Alukaev <br>\n",
    "**Email:** d.alukaev@innopolis.university <br>\n",
    "**Group:** B19-DS-01 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the strategies to improve user experience is to provide user with hints, or, otherwise, to autocomplete his queries. Let's consider suggest.\n",
    "\n",
    "Today we will practice generating suggestions using [Trie](https://en.wikipedia.org/wiki/Trie) data structure (prefix tree), see the example below.\n",
    "\n",
    "Plan of your homework:\n",
    "\n",
    "1. Build Trie based on real search query data, provided by AOL company;\n",
    "2. Generate suggestion based on a trie;\n",
    "3. Measure suggestion speed;\n",
    "4. [M] Add spellcheck to suggest.\n",
    "\n",
    "\n",
    "![image](https://www.ritambhara.in/wp-content/uploads/2017/05/Screen-Shot-2017-05-01-at-4.01.38-PM.png)\n",
    "\n",
    "## 0. Install Trie data structure support\n",
    "\n",
    "You are free to use any library implementation of Trie, as well as the one we suggest (read the docs before asking any questions!): https://github.com/google/pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygtrie\n",
    "import requests\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Check it works and understand the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharTrie(this is 1: A, this is 2: B, that is 3: C)\n",
      "Node = False\n",
      "Subtree = True\n",
      "this is 1 ~ A\n",
      "this is 2 ~ B\n"
     ]
    }
   ],
   "source": [
    "t = pygtrie.CharTrie()\n",
    "\n",
    "# trie can be considered as a form of organizing a set of map\n",
    "t[\"this is 1\"] = \"A\"\n",
    "t[\"this is 2\"] = \"B\"\n",
    "t[\"that is 3\"] = \"C\"\n",
    "\n",
    "print(t)\n",
    "\n",
    "# \"this\" string is present in a set\n",
    "n = t.has_node('this') == pygtrie.Trie.HAS_VALUE\n",
    "# \"this\" prefix is present in a set\n",
    "s = t.has_node('this') == pygtrie.Trie.HAS_SUBTRIE\n",
    "\n",
    "print(f\"Node = {n}\\nSubtree = {s}\")\n",
    "\n",
    "# iterate a subtree\n",
    "for key, val in t.iteritems(\"this\"):\n",
    "    print(key, '~', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a trie upon a dataset\n",
    "\n",
    "### 1.1. [5] Read the dataset\n",
    "\n",
    "Download the [dataset](https://github.com/IUCVLab/information-retrieval/tree/main/datasets/aol) (we provide only the first part of the original data for simplicity (~3.5 mln queries)).\n",
    "\n",
    "Explore the data, see readme file. Load the dataset. Pass the assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_dataset(url, filename=\"aol.txt\", data_dir=\"./data\"):\n",
    "    \"\"\"Download dataset and save it locally.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        link to dataset\n",
    "    \n",
    "    filename : str\n",
    "        name of file with dataset\n",
    "    \n",
    "    data_dir : str\n",
    "        path to directory where dataset located\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    success : bool\n",
    "        whether the dataset was successfully downloaded\n",
    "    \"\"\"\n",
    "    success = False\n",
    "    try:\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "        archivename = f\"{filename}.gz\"\n",
    "        path = os.path.join(data_dir, archivename)\n",
    "        with open(path, 'wb') as f:\n",
    "            r = requests.get(url)\n",
    "            f.write(r.content)\n",
    "        with gzip.open(path) as f:\n",
    "            data = f.read()\n",
    "        path = os.path.join(data_dir, filename)\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(data)\n",
    "        success = True\n",
    "    except:\n",
    "        print(\"Something went wrong. Try to use different link.\")\n",
    "    return success\n",
    "    \n",
    "url = \"https://github.com/IUCVLab/information-retrieval/blob/main/datasets/aol/user-ct-test-collection-01.txt.gz?raw=true\"\n",
    "download_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename=\"aol.txt\", data_dir=\"./data\"):\n",
    "    \"\"\"Read AOL dataset as pandas dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        name of file with dataset\n",
    "    \n",
    "    data_dir : str\n",
    "        path to directory where dataset located\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with AOL dataset\n",
    "    \"\"\"\n",
    "    path = os.path.join(data_dir, filename)\n",
    "    df = pd.read_csv(path, delimiter = \"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aol_data = read_dataset()\n",
    "\n",
    "assert aol_data.shape[0] == 3558411, \"Dataset size does not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnonID</th>\n",
       "      <th>Query</th>\n",
       "      <th>QueryTime</th>\n",
       "      <th>ItemRank</th>\n",
       "      <th>ClickURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187889</th>\n",
       "      <td>6957851</td>\n",
       "      <td>naltrexone</td>\n",
       "      <td>2006-03-28 18:49:54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>http://www.well.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391084</th>\n",
       "      <td>958023</td>\n",
       "      <td>peter walkoviak</td>\n",
       "      <td>2006-03-11 18:28:39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://www.military.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887769</th>\n",
       "      <td>12148249</td>\n",
       "      <td>fuckaroo.com</td>\n",
       "      <td>2006-04-02 01:05:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277750</th>\n",
       "      <td>3190755</td>\n",
       "      <td>www.continental</td>\n",
       "      <td>2006-03-16 21:56:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.continental.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634445</th>\n",
       "      <td>1614554</td>\n",
       "      <td>dresses</td>\n",
       "      <td>2006-03-04 03:52:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215430</th>\n",
       "      <td>7095103</td>\n",
       "      <td>reno tahoe job search</td>\n",
       "      <td>2006-05-16 11:50:44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.jobsearch.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603914</th>\n",
       "      <td>4258929</td>\n",
       "      <td>lodejo en tu manos</td>\n",
       "      <td>2006-03-18 22:51:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809368</th>\n",
       "      <td>2047211</td>\n",
       "      <td>www.pogo.com</td>\n",
       "      <td>2006-05-27 07:16:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.pogo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522591</th>\n",
       "      <td>9037021</td>\n",
       "      <td>palm beach county rmls</td>\n",
       "      <td>2006-03-17 10:49:39</td>\n",
       "      <td>10.0</td>\n",
       "      <td>http://www.mlxpro.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127072</th>\n",
       "      <td>15009582</td>\n",
       "      <td>koaa</td>\n",
       "      <td>2006-03-30 21:58:54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.koaa.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AnonID                   Query            QueryTime  ItemRank  \\\n",
       "2187889   6957851              naltrexone  2006-03-28 18:49:54       2.0   \n",
       "391084     958023         peter walkoviak  2006-03-11 18:28:39       5.0   \n",
       "2887769  12148249            fuckaroo.com  2006-04-02 01:05:16       NaN   \n",
       "1277750   3190755         www.continental  2006-03-16 21:56:29       1.0   \n",
       "634445    1614554                 dresses  2006-03-04 03:52:46       NaN   \n",
       "2215430   7095103   reno tahoe job search  2006-05-16 11:50:44       1.0   \n",
       "1603914   4258929      lodejo en tu manos  2006-03-18 22:51:06       NaN   \n",
       "809368    2047211            www.pogo.com  2006-05-27 07:16:45       1.0   \n",
       "2522591   9037021  palm beach county rmls  2006-03-17 10:49:39      10.0   \n",
       "3127072  15009582                    koaa  2006-03-30 21:58:54       1.0   \n",
       "\n",
       "                           ClickURL  \n",
       "2187889         http://www.well.com  \n",
       "391084      http://www.military.com  \n",
       "2887769                         NaN  \n",
       "1277750  http://www.continental.com  \n",
       "634445                          NaN  \n",
       "2215430    http://www.jobsearch.com  \n",
       "1603914                         NaN  \n",
       "809368          http://www.pogo.com  \n",
       "2522591       http://www.mlxpro.com  \n",
       "3127072         http://www.koaa.com  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aol_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. [10] Build a Trie\n",
    "\n",
    "We want a suggest function to be **non-sensitive to stop words** because we don't want to upset the users if they confuses/omits prepositions. Consider *\"public events in Innopolis\"* vs *\"public events at Innopolis\"* or *\"public events Innopolis\"* - they all mean the same.\n",
    "\n",
    "Build a Trie based on the dataset, **storing query statistics such as query _frequency_, urls and ranks in the nodes**. Some queries may have no associated urls, others may have multiple ranked urls. Think of the way to store this information.\n",
    "\n",
    "Pass the asserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aol_trie = pygtrie.CharTrie()\n",
    "\n",
    "\n",
    "#TODO: build a trie based on the dataset\n",
    "\n",
    "\n",
    "# test trie\n",
    "bag = []\n",
    "for key, val in aol_trie.iteritems(\"sample q\"):\n",
    "    print(key, '~', val)\n",
    "    \n",
    "    #NB: here we assume you store urls in a property of list type. But you can do something different. \n",
    "    bag += val.urls\n",
    "    \n",
    "    assert \"sample question\" in key, \"All examples have `sample question` substring\"\n",
    "    assert key[:len(\"sample question\")] == \"sample question\", \"All examples have `sample question` starting string\"\n",
    "\n",
    "for url in [\"http://www.surveyconnect.com\", \"http://www.custominsight.com\", \n",
    "            \"http://jobsearchtech.about.com\", \"http://www.troy.k12.ny.us\",\n",
    "            \"http://www.flinders.edu.au\", \"http://uscis.gov\"]:\n",
    "    assert url in bag, \"This url should be in a try\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [15] Write a suggest function which is non-sensitive to stop words\n",
    "\n",
    "Suggest options for user query based on Trie you just built.\n",
    "Output results sorted by frequency, print query count for each suggestion. If there is an url available, print the url too. If multiple url-s are available, print the one with the highest rank (the less the better).\n",
    "\n",
    "Pass the asserts.\n",
    "\n",
    "Question for analysis: What is the empirical threshold for minimal prefix for suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set('a on at of to is from for and with using the in &'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_user_query(query: str, trie, top_k=5) -> list[str]:\n",
    "    #TODO: suggest top_k options for a user query\n",
    "    # sort results by frequency (!!), \n",
    "    # suggest the QUERIES for first k ranked urls if available\n",
    "    pass\n",
    "\n",
    "        \n",
    "inp = \"trie\"\n",
    "print(\"Query:\", inp)\n",
    "print(\"Results:\")\n",
    "res = complete_user_query(inp, aol_trie)\n",
    "print(res)\n",
    "\n",
    "#NB we assume you return suggested query string only\n",
    "assert res[0] == \"tried and true tattoo\"\n",
    "assert res[1] == \"triest\" or res[1] == \"triethanalomine\"\n",
    "\n",
    "assert \"boys and girls club of conyers georgia\" \\\n",
    "            in complete_user_query(\"boys girls club conyers\", aol_trie, 10), \"Should be here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure suggest speed ##\n",
    "\n",
    "### 3.1. [10] Full Trie test\n",
    "\n",
    "Check how fast your search is working. Consider changing your code if it takes too long on average.\n",
    "\n",
    "Sucess criterion:\n",
    "- there is an average and variance for **multiple runs** of the given bucket.\n",
    "- there is an average and variance for **multiple runs** of naive search in unindexed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "\n",
    "#TODO: measure avg execution time (in milliseconds) per query and print it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. [M][10] Assess how dataset size affect search time\n",
    "\n",
    "Study the speed of the trie data structure in $\\frac{1}{10}, \\frac{1}{4}, \\frac{1}{2}$, and full dataset. \n",
    "- Sample the data at random.\n",
    "- Plot the graph which shows how search time changes with dataset size.\n",
    "- Compare aganist bruteforce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [10] Add spellchecking to your suggest\n",
    "\n",
    "Try to make your search results as close as possible. Compare top-5 results of each query with top-5 results for corrected.\n",
    "\n",
    "You can use use [pyspellchecker](https://pypi.org/project/pyspellchecker/) `candidates()` call, or use any other spellchecker implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_user_query_with_spellchecker(query, trie, top_k=5) -> list[str]:\n",
    "    #TODO: suggest top_k options for a user query\n",
    "    # sort results by frequency (!!), \n",
    "    # suggest the QUERIES for first k ranked urls if available\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_queries = [\"inormation retrieval\", \"shelrock hol\", \"carnagie mell\", \"babis r\", \"Barrbara \"]\n",
    "inp_queries_corrected = [\"information retrieval\", \"sherlock hol\", \"carnegie mell\", \"babies r\", \"Barbara \"]\n",
    "\n",
    "for q, qc in zip(inp_queries, inp_queries_corrected):\n",
    "    assert  complete_user_query(qc, trie, 5) == \\\n",
    "            complete_user_query_with_spellchecker(q, trie, 5), \"Assert {} and {} give different results\".format(q, qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. [M][20] What if the query is in the middle?\n",
    "\n",
    "Modify your code to suggest string even if the query is found **in the middle** of the text. Think about techniques you can borrow from our previous classes, e.g. about wildcard search.\n",
    "\n",
    "E.g. `Semantic Parsing` in \n",
    "\n",
    "```\n",
    "3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-scale 3D Point Clouds\n",
    "                                                           ~~~~~~~~~~~~~~~~\n",
    "```\n",
    "\n",
    "**NB**: Please extend you trie-based approach. Even if using `in` and regexp can give you same result, this is not a scalable approach, which we will not accept.\n",
    "\n",
    "Pass the asserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrie = None\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "def complete_user_query_with_spellchecker_and_middle(query, trie, top_k=5) -> list[str]:\n",
    "    #TODO: suggest top_k options for a user query\n",
    "    # sort results by frequency (!!), \n",
    "    # suggest the QUERIES for first k ranked urls if available\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"ricky martin beach\" in complete_user_query_with_spellchecker_and_middle(\n",
    "            \"martin beach\", newtrie, 20)\n",
    "assert \"free adult movie\" in  complete_user_query_with_spellchecker_and_middle(\n",
    "            \"adult movie\", newtrie, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [M][20] Enrich your suggest with search results\n",
    "\n",
    "Your users will be happy if at typing the query they will see not only suggested queries, but also snippets of the answers to these queries!\n",
    "\n",
    "Imagine you type \"continental air\", and the search engine suggests you \"continental airlines\" together with the URL and snippet kind of `\"Continental Airlines was a major American airline founded in 1934 and eventually headquartered in Houston, Texas...\"`, which you borrow from the search engine snippet. How can you add existing search enginge to your code? [One](https://yandex.com/dev/xml/doc/dg/task/quickstart.html), [two](https://docs.microsoft.com/en-us/bing/search-apis/bing-web-search/search-the-web), [three](https://searx.roughs.ru/), ...\n",
    "\n",
    "Improve your suggest. It should return a tuple of 3 instead on a string: `(query, text, url)`. Write your own tests which will for the query `continental air` return among the results:\n",
    "1. `query` = `continental airlines`.\n",
    "2. \n",
    "`Continental Airlines was a major American airline founded in 1934` in `text`.\n",
    "3. `url` = `https://en.wikipedia.org/wiki/Continental_Airlines`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_user_query_with_spellchecker_and_middle_with_snippets(query, trie, top_k=5) -> list[tuple]:\n",
    "    #TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TESTS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
