{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment 4 - Sugges_\n",
    "\n",
    "**Author:** Danis Alukaev <br>\n",
    "**Email:** d.alukaev@innopolis.university <br>\n",
    "**Group:** B19-DS-01 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the strategies to improve user experience is to provide user with hints, or, otherwise, to autocomplete his queries. Let's consider suggest.\n",
    "\n",
    "Today we will practice generating suggestions using [Trie](https://en.wikipedia.org/wiki/Trie) data structure (prefix tree), see the example below.\n",
    "\n",
    "Plan of your homework:\n",
    "\n",
    "1. Build Trie based on real search query data, provided by AOL company;\n",
    "2. Generate suggestion based on a trie;\n",
    "3. Measure suggestion speed;\n",
    "4. [M] Add spellcheck to suggest.\n",
    "\n",
    "\n",
    "![image](https://www.ritambhara.in/wp-content/uploads/2017/05/Screen-Shot-2017-05-01-at-4.01.38-PM.png)\n",
    "\n",
    "## 0. Install Trie data structure support\n",
    "\n",
    "You are free to use any library implementation of Trie, as well as the one we suggest (read the docs before asking any questions!): https://github.com/google/pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygtrie\n",
    "import requests\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Check it works and understand the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharTrie(this is 1: A, this is 2: B, that is 3: C)\n",
      "Node = False\n",
      "Subtree = True\n",
      "this is 1 ~ A\n",
      "this is 2 ~ B\n"
     ]
    }
   ],
   "source": [
    "t = pygtrie.CharTrie()\n",
    "\n",
    "# trie can be considered as a form of organizing a set of map\n",
    "t[\"this is 1\"] = \"A\"\n",
    "t[\"this is 2\"] = \"B\"\n",
    "t[\"that is 3\"] = \"C\"\n",
    "\n",
    "print(t)\n",
    "\n",
    "# \"this\" string is present in a set\n",
    "n = t.has_node('this') == pygtrie.Trie.HAS_VALUE\n",
    "# \"this\" prefix is present in a set\n",
    "s = t.has_node('this') == pygtrie.Trie.HAS_SUBTRIE\n",
    "\n",
    "print(f\"Node = {n}\\nSubtree = {s}\")\n",
    "\n",
    "# iterate a subtree\n",
    "for key, val in t.iteritems(\"this\"):\n",
    "    print(key, '~', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a trie upon a dataset\n",
    "\n",
    "### 1.1. [5] Read the dataset\n",
    "\n",
    "Download the [dataset](https://github.com/IUCVLab/information-retrieval/tree/main/datasets/aol) (we provide only the first part of the original data for simplicity (~3.5 mln queries)).\n",
    "\n",
    "Explore the data, see readme file. Load the dataset. Pass the assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_dataset(url, filename=\"aol.txt\", data_dir=\"./data\"):\n",
    "    \"\"\"Download dataset and save it locally.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        link to dataset\n",
    "    \n",
    "    filename : str\n",
    "        name of file with dataset\n",
    "    \n",
    "    data_dir : str\n",
    "        path to directory where dataset located\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    success : bool\n",
    "        whether the dataset was successfully downloaded\n",
    "    \"\"\"\n",
    "    success = False\n",
    "    try:\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "        archivename = f\"{filename}.gz\"\n",
    "        path = os.path.join(data_dir, archivename)\n",
    "        with open(path, 'wb') as f:\n",
    "            r = requests.get(url)\n",
    "            f.write(r.content)\n",
    "        with gzip.open(path) as f:\n",
    "            data = f.read()\n",
    "        path = os.path.join(data_dir, filename)\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(data)\n",
    "        success = True\n",
    "    except:\n",
    "        print(\"Something went wrong. Try to use different link.\")\n",
    "    return success\n",
    "    \n",
    "url = \"https://github.com/IUCVLab/information-retrieval/blob/main/datasets/aol/user-ct-test-collection-01.txt.gz?raw=true\"\n",
    "download_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename=\"aol.txt\", data_dir=\"./data\"):\n",
    "    \"\"\"Read AOL dataset as pandas dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        name of file with dataset\n",
    "    \n",
    "    data_dir : str\n",
    "        path to directory where dataset located\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with AOL dataset\n",
    "    \"\"\"\n",
    "    path = os.path.join(data_dir, filename)\n",
    "    df = pd.read_csv(path, delimiter = \"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aol_data = read_dataset()\n",
    "\n",
    "assert aol_data.shape[0] == 3558411, \"Dataset size does not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnonID</th>\n",
       "      <th>Query</th>\n",
       "      <th>QueryTime</th>\n",
       "      <th>ItemRank</th>\n",
       "      <th>ClickURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2381084</th>\n",
       "      <td>8097799</td>\n",
       "      <td>mapquest</td>\n",
       "      <td>2006-05-20 09:58:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487027</th>\n",
       "      <td>22839090</td>\n",
       "      <td>google</td>\n",
       "      <td>2006-05-28 20:20:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160079</th>\n",
       "      <td>6781296</td>\n",
       "      <td>printable airsoft targets</td>\n",
       "      <td>2006-05-21 19:22:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.airsoft-guns.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435648</th>\n",
       "      <td>21245737</td>\n",
       "      <td>zachery construction company</td>\n",
       "      <td>2006-05-08 23:13:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361859</th>\n",
       "      <td>883390</td>\n",
       "      <td>marriagemindedpeoplemeet</td>\n",
       "      <td>2006-05-02 17:26:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256144</th>\n",
       "      <td>3149842</td>\n",
       "      <td>coupon codes</td>\n",
       "      <td>2006-03-02 10:47:09</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://www.coupon-codes.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216084</th>\n",
       "      <td>3042841</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>2006-04-28 15:44:15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>http://search.yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>91602</td>\n",
       "      <td>spinal facet fusion via injection</td>\n",
       "      <td>2006-04-02 17:22:17</td>\n",
       "      <td>13.0</td>\n",
       "      <td>http://www.aafp.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377443</th>\n",
       "      <td>8076981</td>\n",
       "      <td>haverhill country club</td>\n",
       "      <td>2006-05-03 07:14:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.haverhillcc.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883318</th>\n",
       "      <td>2235233</td>\n",
       "      <td>religious checks</td>\n",
       "      <td>2006-05-05 12:12:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AnonID                              Query            QueryTime  \\\n",
       "2381084   8097799                           mapquest  2006-05-20 09:58:51   \n",
       "3487027  22839090                             google  2006-05-28 20:20:21   \n",
       "2160079   6781296          printable airsoft targets  2006-05-21 19:22:07   \n",
       "3435648  21245737       zachery construction company  2006-05-08 23:13:31   \n",
       "361859     883390           marriagemindedpeoplemeet  2006-05-02 17:26:17   \n",
       "1256144   3149842                       coupon codes  2006-03-02 10:47:09   \n",
       "1216084   3042841                              yahoo  2006-04-28 15:44:15   \n",
       "37262       91602  spinal facet fusion via injection  2006-04-02 17:22:17   \n",
       "2377443   8076981             haverhill country club  2006-05-03 07:14:56   \n",
       "883318    2235233                   religious checks  2006-05-05 12:12:12   \n",
       "\n",
       "         ItemRank                       ClickURL  \n",
       "2381084       NaN                            NaN  \n",
       "3487027       NaN                            NaN  \n",
       "2160079       1.0  http://www.airsoft-guns.co.uk  \n",
       "3435648       NaN                            NaN  \n",
       "361859        NaN                            NaN  \n",
       "1256144       5.0    http://www.coupon-codes.net  \n",
       "1216084       2.0        http://search.yahoo.com  \n",
       "37262        13.0            http://www.aafp.org  \n",
       "2377443       1.0     http://www.haverhillcc.com  \n",
       "883318        NaN                            NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aol_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. [10] Build a Trie\n",
    "\n",
    "We want a suggest function to be **non-sensitive to stop words** because we don't want to upset the users if they confuses/omits prepositions. Consider *\"public events in Innopolis\"* vs *\"public events at Innopolis\"* or *\"public events Innopolis\"* - they all mean the same.\n",
    "\n",
    "Build a Trie based on the dataset, **storing query statistics such as query _frequency_, urls and ranks in the nodes**. Some queries may have no associated urls, others may have multiple ranked urls. Think of the way to store this information.\n",
    "\n",
    "Pass the asserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedList(list):\n",
    "    \"\"\"List with extended properties.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        super().__init__(args)\n",
    "        self._init_properties(args)\n",
    "    \n",
    "    def _init_properties(self, args):\n",
    "        \"\"\"Initialize additional properties. \n",
    "        \n",
    "        Supposed that for each new values of list, it\n",
    "        will be reinitialized, i.e. work as a tuple.\n",
    "        Expected for elements: frequency, list of urls,\n",
    "        list of ranks, and list or original queries.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        args : objects\n",
    "            objects to store in the list\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.frequency = args[0]\n",
    "        self.urls = args[1]\n",
    "        self.ranks = args[2]\n",
    "        self.queries = args[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c97bd6df0884cda905e4fe3a7b87348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3558411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_aol_trie(aol_data, stops):\n",
    "    \"\"\"Build a trie based on AOL dataset.\n",
    "    \n",
    "    Iteratively adds queries to the trie. In case if query is already \n",
    "    in the trie, adds new urls and ranks to the node. Excludes stop words \n",
    "    from the query. Utilizes ExtendedList for nodes. The attributes are \n",
    "    frequency, list of urls, list of ranks and list of original queries (e.g. \n",
    "    useful in case if propositions in similar queries vary). \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    aol_data : pandas.DataFrame\n",
    "        AOL dataset\n",
    "    \n",
    "    stops : set\n",
    "        set of stop words\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    trie : pygtrie.CharTrie\n",
    "        trie based on AOL dataset\n",
    "    \"\"\"\n",
    "    trie = pygtrie.CharTrie()\n",
    "    data = aol_data.reset_index()\n",
    "    freqs = data.Query.value_counts()\n",
    "    \n",
    "    convert_nan = lambda x: None if x != x else x\n",
    "    \n",
    "    for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        query = row.Query\n",
    "        if query != query:\n",
    "            continue\n",
    "        freq = convert_nan(freqs[query])\n",
    "        queries = [query[:]]\n",
    "        query = \" \".join([w for w in query.split() if w not in stops])\n",
    "        \n",
    "        urls = [convert_nan(row.ClickURL)]\n",
    "        ranks = [convert_nan(row.ItemRank)]\n",
    "        \n",
    "        if query in trie:\n",
    "            _, _urls, _ranks, _queries = trie[query]\n",
    "            urls, ranks, queries = _urls + urls, _ranks + ranks, _queries + queries\n",
    "        trie[query] = ExtendedList(freq, urls, ranks, queries)\n",
    "    return trie\n",
    "\n",
    "stops = set('a on at of to is from for and with using the in &'.split())\n",
    "aol_trie = build_aol_trie(aol_data, stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample question surveys ~ [5, ['http://www.surveyconnect.com', 'http://www.custominsight.com', 'http://www.askemployees.com', 'http://www.lg-employers.gov.uk', None], [7.0, 4.0, 10.0, 1.0, None], ['sample question surveys', 'sample question surveys', 'sample question surveys', 'sample question surveys', 'sample question surveys']]\n",
      "sample questions immigration interview ~ [1, [None], [None], ['sample questions for immigration interview']]\n",
      "sample questions interview ~ [1, ['http://www.quintcareers.com'], [1.0], ['sample questions for interview']]\n",
      "sample questions family interview ~ [3, ['http://www.grandparents-day.com', 'http://www.quintcareers.com', 'http://jobsearchtech.about.com'], [2.0, 5.0, 3.0], ['sample questions for family interview', 'sample questions for family interview', 'sample questions for family interview']]\n",
      "sample questions sociology race ethnicity ~ [1, [None], [None], ['sample questions sociology race and ethnicity']]\n",
      "sample questions biology ~ [2, ['http://www.utexas.edu', 'http://www.troy.k12.ny.us'], [3.0, 6.0], ['sample questions biology', 'sample questions biology']]\n",
      "sample questions us citizenship test ~ [1, ['http://uscis.gov'], [1.0], ['sample questions for us citizenship test']]\n",
      "sample questionarie teaching evaluation ~ [1, [None], [None], ['sample questionarie teaching evaluation']]\n",
      "sample questionnaire teaching evaluation ~ [5, ['http://www.surveyconsole.com', 'http://www.usask.ca', 'http://teaching.berkeley.edu', 'http://www.flinders.edu.au', 'http://oregonstate.edu'], [1.0, 2.0, 6.0, 9.0, 10.0], ['sample questionnaire teaching evaluation', 'sample questionnaire teaching evaluation', 'sample questionnaire teaching evaluation', 'sample questionnaire teaching evaluation', 'sample questionnaire teaching evaluation']]\n",
      "sample questionnaire clinical research coordinators certification ~ [1, ['http://www.pharmatech.com'], [9.0], ['sample questionnaire for clinical research coordinators certification']]\n"
     ]
    }
   ],
   "source": [
    "# test trie\n",
    "bag = []\n",
    "for key, val in aol_trie.iteritems(\"sample q\"):\n",
    "    print(key, '~', val)\n",
    "    \n",
    "    #NB: here we assume you store urls in a property of list type. But you can do something different. \n",
    "    bag += val.urls\n",
    "    \n",
    "    assert \"sample question\" in key, \"All examples have `sample question` substring\"\n",
    "    assert key[:len(\"sample question\")] == \"sample question\", \"All examples have `sample question` starting string\"\n",
    "\n",
    "for url in [\"http://www.surveyconnect.com\", \"http://www.custominsight.com\", \n",
    "            \"http://jobsearchtech.about.com\", \"http://www.troy.k12.ny.us\",\n",
    "            \"http://www.flinders.edu.au\", \"http://uscis.gov\"]:\n",
    "    assert url in bag, \"This url should be in a try\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [15] Write a suggest function which is non-sensitive to stop words\n",
    "\n",
    "Suggest options for user query based on Trie you just built.\n",
    "Output results sorted by frequency, print query count for each suggestion. If there is an url available, print the url too. If multiple url-s are available, print the one with the highest rank (the less the better).\n",
    "\n",
    "Pass the asserts.\n",
    "\n",
    "Question for analysis: What is the empirical threshold for minimal prefix for suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set('a on at of to is from for and with using the in &'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! Important\n",
    "\n",
    "While using `Python 3.8.12` there is a problem with typing `list[str]`. For this reason I'm importing type `List` from typing and change the return type to `List[str]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def complete_user_query(query: str, trie, top_k=5, verbose=False) -> List[str]:\n",
    "    \"\"\"Complete user query using Trie.\n",
    "    \n",
    "    Suggests top k options for a user query. Retrieves possible\n",
    "    options from the Trie. Sorts them by frequency and takes k most\n",
    "    frequent. Outputs to stdout the query count, suggestion, url with \n",
    "    highest rank, and rank itself. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        user query\n",
    "    \n",
    "    trie : pygtrie.CharTrie\n",
    "        Trie used for completion\n",
    "    \n",
    "    top_k : int (default: 5)\n",
    "        number of suggestions to retrieve\n",
    "    \n",
    "    verbose : bool (default: False)\n",
    "        whether output the meta data such as query count, \n",
    "        suggestion, url with highest rank, and rank itself\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    completions : list\n",
    "        list of user query completion options sorted\n",
    "        by frequency\n",
    "    \n",
    "    \"\"\"\n",
    "    _query = query[:]\n",
    "    for stop in stops:\n",
    "        _query.replace(stop, \"\")\n",
    "    _query.replace(\"  \", \" \")\n",
    "    \n",
    "    items = list(trie.iteritems(_query))\n",
    "    suggestions = sorted(items, key=lambda x: x[1][0], reverse=True)\n",
    "    top_k = min(top_k, len(suggestions))\n",
    "    top = suggestions[:top_k]\n",
    "    \n",
    "    if not verbose:\n",
    "        meta = {}\n",
    "        for idx, suggestion in enumerate(top):\n",
    "            freq, urls, ranks, queries = suggestion[1]\n",
    "            query = Counter(queries).most_common(1)[0][0]\n",
    "            \n",
    "            meta[idx + 1] = {\n",
    "                \"Suggestion\": query,\n",
    "                \"Query Count\": freq, \n",
    "            }\n",
    "            ranked_urls = list(zip(urls, ranks))\n",
    "            ranked_urls = [p for p in ranked_urls if p[0] is not None and p[1] is not None]\n",
    "            ranked_urls = sorted(ranked_urls, key=lambda x: x[1])\n",
    "            if len(ranked_urls) > 0:\n",
    "                meta[idx + 1][\"URL\"] = ranked_urls[0][0]\n",
    "                meta[idx + 1][\"URL rank\"] = ranked_urls[0][1]\n",
    "        print(\"\\n---------OUTPUT---------\")\n",
    "        pprint(meta)\n",
    "        print(\"-------END OUTPUT-------\\n\")\n",
    "\n",
    "    completions = [Counter(s[1][3]).most_common(1)[0][0] for s in top]\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: trie\n",
      "Results:\n",
      "\n",
      "---------OUTPUT---------\n",
      "{1: {'Query Count': 5,\n",
      "     'Suggestion': 'tried and true tattoo',\n",
      "     'URL': 'http://www.triedntruetattoo.com',\n",
      "     'URL rank': 1.0},\n",
      " 2: {'Query Count': 3, 'Suggestion': 'triest'},\n",
      " 3: {'Query Count': 3,\n",
      "     'Suggestion': 'triethanalomine',\n",
      "     'URL': 'http://avalon.unomaha.edu',\n",
      "     'URL rank': 1.0},\n",
      " 4: {'Query Count': 2, 'Suggestion': 'tried and failed'},\n",
      " 5: {'Query Count': 1,\n",
      "     'Suggestion': \"tried and truechildren's consignment sale\"}}\n",
      "-------END OUTPUT-------\n",
      "\n",
      "['tried and true tattoo', 'triest', 'triethanalomine', 'tried and failed', \"tried and truechildren's consignment sale\"]\n",
      "\n",
      "---------OUTPUT---------\n",
      "{1: {'Query Count': 2,\n",
      "     'Suggestion': 'boys and girls club of conyers georgia',\n",
      "     'URL': 'http://www.bgcma.org',\n",
      "     'URL rank': 1.0}}\n",
      "-------END OUTPUT-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = \"trie\"\n",
    "print(\"Query:\", inp)\n",
    "print(\"Results:\")\n",
    "res = complete_user_query(inp, aol_trie)\n",
    "print(res)\n",
    "\n",
    "#NB we assume you return suggested query string only\n",
    "assert res[0] == \"tried and true tattoo\"\n",
    "assert res[1] == \"triest\" or res[1] == \"triethanalomine\"\n",
    "\n",
    "assert \"boys and girls club of conyers georgia\" \\\n",
    "            in complete_user_query(\"boys girls club conyers\", aol_trie, 10), \"Should be here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure suggest speed ##\n",
    "\n",
    "### 3.1. [10] Full Trie test\n",
    "\n",
    "Check how fast your search is working. Consider changing your code if it takes too long on average.\n",
    "\n",
    "Sucess criterion:\n",
    "- there is an average and variance for **multiple runs** of the given bucket.\n",
    "- there is an average and variance for **multiple runs** of naive search in unindexed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "\n",
    "#TODO: measure avg execution time (in milliseconds) per query and print it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [10] Add spellchecking to your suggest\n",
    "\n",
    "Try to make your search results as close as possible. Compare top-5 results of each query with top-5 results for corrected.\n",
    "\n",
    "You can use use [pyspellchecker](https://pypi.org/project/pyspellchecker/) `candidates()` call, or use any other spellchecker implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_user_query_with_spellchecker(query, trie, top_k=5) -> list[str]:\n",
    "    #TODO: suggest top_k options for a user query\n",
    "    # sort results by frequency (!!), \n",
    "    # suggest the QUERIES for first k ranked urls if available\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_queries = [\"inormation retrieval\", \"shelrock hol\", \"carnagie mell\", \"babis r\", \"Barrbara \"]\n",
    "inp_queries_corrected = [\"information retrieval\", \"sherlock hol\", \"carnegie mell\", \"babies r\", \"Barbara \"]\n",
    "\n",
    "for q, qc in zip(inp_queries, inp_queries_corrected):\n",
    "    assert  complete_user_query(qc, trie, 5) == \\\n",
    "            complete_user_query_with_spellchecker(q, trie, 5), \"Assert {} and {} give different results\".format(q, qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
